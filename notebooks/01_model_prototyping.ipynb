{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c99b53d",
   "metadata": {},
   "source": [
    "# ST-GNN Model Prototyping and Development\n",
    "\n",
    "This notebook provides a complete walkthrough of the Spatio-Temporal Graph Neural Network (ST-GNN) model development for human motion prediction in the Predictive Human-Robot Collaboration system.\n",
    "\n",
    "## Objectives\n",
    "1. Explore the Human3.6M dataset structure\n",
    "2. Implement and test the ST-GNN architecture\n",
    "3. Train the model with sample data\n",
    "4. Evaluate prediction performance\n",
    "5. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import h5py\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ba88b",
   "metadata": {},
   "source": [
    "## 1. Data Generation and Exploration\n",
    "\n",
    "Since we don't have the actual Human3.6M dataset, let's create synthetic data that mimics the structure for prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic human motion data\n",
    "def generate_synthetic_motion_data(num_sequences=1000, seq_length=75, num_joints=34):\n",
    "    \"\"\"Generate synthetic human motion data that mimics realistic movement patterns.\"\"\"\n",
    "    data = np.zeros((num_sequences, seq_length, num_joints, 3))\n",
    "    \n",
    "    for seq in range(num_sequences):\n",
    "        # Generate different motion patterns\n",
    "        motion_type = seq % 4\n",
    "        \n",
    "        for frame in range(seq_length):\n",
    "            t = frame / 30.0  # Time in seconds\n",
    "            \n",
    "            for joint in range(num_joints):\n",
    "                if motion_type == 0:  # Walking pattern\n",
    "                    data[seq, frame, joint, 0] = 0.2 * np.sin(2 * np.pi * 1.0 * t + joint * 0.1)\n",
    "                    data[seq, frame, joint, 1] = 0.1 * np.cos(2 * np.pi * 0.5 * t + joint * 0.2)\n",
    "                    data[seq, frame, joint, 2] = 1.5 + 0.1 * np.sin(2 * np.pi * 2.0 * t + joint * 0.15)\n",
    "                elif motion_type == 1:  # Arm reaching\n",
    "                    data[seq, frame, joint, 0] = 0.3 * np.sin(2 * np.pi * 0.3 * t) if joint in [11, 12, 13, 14, 15, 16] else 0\n",
    "                    data[seq, frame, joint, 1] = 0.2 * np.cos(2 * np.pi * 0.4 * t) if joint in [11, 12, 13, 14, 15, 16] else 0\n",
    "                    data[seq, frame, joint, 2] = 1.0 + 0.05 * np.sin(2 * np.pi * 1.5 * t)\n",
    "                elif motion_type == 2:  # Sitting motion\n",
    "                    data[seq, frame, joint, 0] = 0.05 * np.sin(2 * np.pi * 0.1 * t + joint * 0.05)\n",
    "                    data[seq, frame, joint, 1] = 0.03 * np.cos(2 * np.pi * 0.15 * t + joint * 0.1)\n",
    "                    data[seq, frame, joint, 2] = 1.2 + 0.02 * np.sin(2 * np.pi * 0.5 * t + joint * 0.2)\n",
    "                else:  # General movement\n",
    "                    data[seq, frame, joint, 0] = 0.1 * np.sin(2 * np.pi * 0.7 * t + joint * 0.1)\n",
    "                    data[seq, frame, joint, 1] = 0.1 * np.cos(2 * np.pi * 0.8 * t + joint * 0.15)\n",
    "                    data[seq, frame, joint, 2] = 1.0 + 0.05 * np.sin(2 * np.pi * 1.2 * t + joint * 0.3)\n",
    "                \n",
    "                # Add some noise\n",
    "                data[seq, frame, joint] += np.random.normal(0, 0.005, 3)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate training data\n",
    "print(\"Generating synthetic motion data...\")\n",
    "motion_data = generate_synthetic_motion_data(num_sequences=1000, seq_length=75, num_joints=34)\n",
    "print(f\"Generated data shape: {motion_data.shape}\")\n",
    "print(\"Shape interpretation: (sequences, frames, joints, coordinates)\")\n",
    "\n",
    "# Split into input and target sequences\n",
    "input_seq_len = 30\n",
    "output_seq_len = 45\n",
    "\n",
    "input_sequences = motion_data[:, :input_seq_len, :, :]  # First 30 frames\n",
    "target_sequences = motion_data[:, input_seq_len:, :, :]  # Next 45 frames\n",
    "\n",
    "print(f\"Input sequences shape: {input_sequences.shape}\")\n",
    "print(f\"Target sequences shape: {target_sequences.shape}\")\n",
    "\n",
    "# Visualize a sample sequence\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot a few joints over time for one sequence\n",
    "sample_seq = 0\n",
    "joints_to_plot = [0, 8, 11, 14]  # Hip, Neck, Left shoulder, Right shoulder\n",
    "joint_names = ['Hip', 'Neck', 'L_Shoulder', 'R_Shoulder']\n",
    "\n",
    "for i, (joint_idx, joint_name) in enumerate(zip(joints_to_plot, joint_names)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    \n",
    "    # Plot x, y, z coordinates\n",
    "    frames = range(75)\n",
    "    plt.plot(frames, motion_data[sample_seq, :, joint_idx, 0], 'r-', label='X', alpha=0.7)\n",
    "    plt.plot(frames, motion_data[sample_seq, :, joint_idx, 1], 'g-', label='Y', alpha=0.7)\n",
    "    plt.plot(frames, motion_data[sample_seq, :, joint_idx, 2], 'b-', label='Z', alpha=0.7)\n",
    "    \n",
    "    # Mark the split between input and target\n",
    "    plt.axvline(x=input_seq_len, color='black', linestyle='--', alpha=0.5, label='Split')\n",
    "    \n",
    "    plt.title(f'{joint_name} Joint Motion')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Position (m)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data generation complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
